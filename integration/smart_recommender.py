# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ¨è–¦å™¨ (Smart Recommender)
åˆ†æå­¸å“¡å¯¦ä½œä¸­çš„éŒ¯èª¤ï¼Œè­˜åˆ¥çŸ¥è­˜ç›²é»ï¼Œæ¨è–¦ç†è«–è¤‡ç¿’ä¸»é¡Œ
"""

from typing import Dict, List, Optional, Set
from collections import defaultdict, Counter
import json
from pathlib import Path


class SmartRecommender:
    """
    æ™ºèƒ½æ¨è–¦å™¨

    è·è²¬ï¼š
    1. åˆ†æå¯¦ä½œæ“ä½œå¤±æ•—åŸå› 
    2. è­˜åˆ¥çŸ¥è­˜ç›²é»
    3. æ¨è–¦ç†è«–è¤‡ç¿’ä¸»é¡Œ
    4. ç”Ÿæˆå€‹æ€§åŒ–å­¸ç¿’è·¯å¾‘

    ä½¿ç”¨ç¯„ä¾‹ï¼š
    ```python
    recommender = SmartRecommender()

    # åˆ†æå¤±æ•—æ“ä½œ
    failed_ops = [
        {"operation": "æª¢æŸ¥å†·å»æ°´æµé‡", "topic": "å†·å»ç³»çµ±"},
        {"operation": "èª¿æ•´çœŸç©ºå£“åŠ›", "topic": "çœŸç©ºç³»çµ±"}
    ]

    # ç²å–æ¨è–¦
    recommendations = recommender.analyze_and_recommend(failed_ops, knowledge_gaps)
    ```
    """

    # æ“ä½œé¡å‹åˆ°ç†è«–ä¸»é¡Œçš„æ˜ å°„
    OPERATION_TOPIC_MAPPING = {
        # å†·å»ç³»çµ±ç›¸é—œ
        "å†·å»": {
            "topics": ["å†·å»ç³»çµ±åŸç†", "ç†±ç®¡ç†åŸºç¤", "éæ¿¾ç¶²ç¶­è­·", "å†·å»æ¶²å¾ªç’°"],
            "priority": "high",
            "keywords": ["å†·å»", "é™æº«", "æ•£ç†±", "æ°´æµ", "é¢¨æ‰‡", "æº«åº¦éé«˜"]
        },

        # çœŸç©ºç³»çµ±ç›¸é—œ
        "çœŸç©º": {
            "topics": ["çœŸç©ºç³»çµ±åŸç†", "çœŸç©ºæ³µæ“ä½œ", "æ´©æ¼æª¢æ¸¬", "çœŸç©ºåº¦æ§åˆ¶"],
            "priority": "high",
            "keywords": ["çœŸç©º", "å£“åŠ›", "æŠ½æ°£", "æ´©æ¼", "çœŸç©ºæ³µ", "çœŸç©ºåº¦"]
        },

        # å°æº–ç³»çµ±ç›¸é—œ
        "å°æº–": {
            "topics": ["å°æº–ç³»çµ±åŸç†", "æ©Ÿæ¢°ç©©å®šæ€§", "æŒ¯å‹•æ§åˆ¶", "ç²¾å¯†å®šä½"],
            "priority": "medium",
            "keywords": ["å°æº–", "å®šä½", "åç§»", "ç²¾åº¦", "æ ¡æº–", "æŒ¯å‹•"]
        },

        # å…‰å­¸ç³»çµ±ç›¸é—œ
        "å…‰å­¸": {
            "topics": ["å…‰å­¸ç³»çµ±åŸç†", "é¡ç‰‡æ¸…æ½”ç¶­è­·", "å…‰æºç®¡ç†", "å…‰è·¯èª¿æ•´"],
            "priority": "high",
            "keywords": ["å…‰å­¸", "é¡ç‰‡", "é€é¡", "å…‰æº", "èšç„¦", "å…‰è·¯"]
        },

        # æº«åº¦æ§åˆ¶ç›¸é—œ
        "æº«åº¦": {
            "topics": ["æº«æ§ç³»çµ±åŸç†", "ç†±å¹³è¡¡åŸç†", "æº«åº¦æ„Ÿæ¸¬å™¨", "PIDæ§åˆ¶"],
            "priority": "high",
            "keywords": ["æº«åº¦", "æº«æ§", "åŠ ç†±", "æ†æº«", "ç†±å¹³è¡¡", "æº«åº¦æ³¢å‹•"]
        },

        # å£“åŠ›æ§åˆ¶ç›¸é—œ
        "å£“åŠ›": {
            "topics": ["å£“åŠ›æ§åˆ¶åŸç†", "æ°£é«”ä¾›æ‡‰ç³»çµ±", "å£“åŠ›æ„Ÿæ¸¬å™¨", "å£“åŠ›èª¿ç¯€"],
            "priority": "medium",
            "keywords": ["å£“åŠ›", "æ°£å£“", "èª¿å£“", "å£“åŠ›è¡¨", "æ°£é«”", "å£“åŠ›æ³¢å‹•"]
        },

        # åŒ–å­¸ç›¸é—œ
        "åŒ–å­¸": {
            "topics": ["CVDåŸç†", "åŒ–å­¸åæ‡‰", "æ°£é«”åŒ–å­¸", "æ²‰ç©æ©Ÿåˆ¶"],
            "priority": "medium",
            "keywords": ["åŒ–å­¸", "åæ‡‰", "æ°£é«”", "cvd", "æ²‰ç©", "åŒ–å­¸å“"]
        },

        # é›»æ°£ç›¸é—œ
        "é›»æ°£": {
            "topics": ["é›»æ°£ç³»çµ±åŸç†", "é›»æºç®¡ç†", "æ¥åœ°èˆ‡å®‰å…¨", "é›»æ°£æ•…éšœæ’é™¤"],
            "priority": "low",
            "keywords": ["é›»æ°£", "é›»æº", "é›»å£“", "é›»æµ", "çŸ­è·¯", "æ–·è·¯"]
        },

        # æ©Ÿæ¢°ç›¸é—œ
        "æ©Ÿæ¢°": {
            "topics": ["æ©Ÿæ¢°çµæ§‹", "å‚³å‹•ç³»çµ±", "æ½¤æ»‘ç¶­è­·", "æ©Ÿæ¢°æ•…éšœè¨ºæ–·"],
            "priority": "low",
            "keywords": ["æ©Ÿæ¢°", "é¦¬é”", "è»¸æ‰¿", "å‚³å‹•", "å¡ä½", "æ‘©æ“¦"]
        },

        # å®‰å…¨èˆ‡ç·Šæ€¥è™•ç†
        "å®‰å…¨": {
            "topics": ["å®‰å…¨è¦ç¯„", "ç·Šæ€¥åœæ©Ÿç¨‹åº", "SOPæ¨™æº–", "é¢¨éšªè©•ä¼°"],
            "priority": "critical",
            "keywords": ["å®‰å…¨", "ç·Šæ€¥", "åœæ©Ÿ", "è­¦å ±", "sop", "é¢¨éšª"]
        }
    }

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½æ¨è–¦å™¨

        Args:
            config_path: é…ç½®æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        self.config = self._load_config(config_path) if config_path else {}

        # æ¨è–¦æ­·å²
        self.recommendation_history = []

    def _load_config(self, config_path: str) -> Dict:
        """è¼‰å…¥é…ç½®æª”æ¡ˆ"""
        path = Path(config_path)
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def analyze_failed_operations(self, failed_operations: List[Dict]) -> Dict:
        """
        åˆ†æå¤±æ•—çš„æ“ä½œ

        Args:
            failed_operations: å¤±æ•—æ“ä½œåˆ—è¡¨ï¼Œæ¯é …åŒ…å«ï¼š
                {
                    "operation": str,  # æ“ä½œæè¿°
                    "topic": str,      # ä¸»é¡Œï¼ˆå¯é¸ï¼‰
                    "error_type": str  # éŒ¯èª¤é¡å‹ï¼ˆå¯é¸ï¼‰
                }

        Returns:
            åˆ†æçµæœï¼š
            {
                "total_failures": int,
                "failure_by_category": {...},
                "identified_topics": [...]
            }
        """
        failure_categories = defaultdict(int)
        identified_topics = set()

        for operation in failed_operations:
            op_text = operation.get("operation", "").lower()
            topic = operation.get("topic", "unknown")

            # æ ¹æ“šæ“ä½œå…§å®¹è­˜åˆ¥é¡åˆ¥
            for category, mapping in self.OPERATION_TOPIC_MAPPING.items():
                if any(keyword in op_text for keyword in mapping["keywords"]):
                    failure_categories[category] += 1
                    identified_topics.update(mapping["topics"])

        return {
            "total_failures": len(failed_operations),
            "failure_by_category": dict(failure_categories),
            "identified_topics": list(identified_topics)
        }

    def analyze_knowledge_gaps(self, knowledge_gaps: List[Dict]) -> Dict:
        """
        åˆ†æçŸ¥è­˜ç›²é»

        Args:
            knowledge_gaps: çŸ¥è­˜ç›²é»åˆ—è¡¨ï¼ˆä¾†è‡ª ProgressTrackerï¼‰

        Returns:
            åˆ†æçµæœï¼š
            {
                "critical_gaps": [...],  # åš´é‡ç›²é»
                "moderate_gaps": [...],   # ä¸­ç­‰ç›²é»
                "minor_gaps": [...]       # è¼•å¾®ç›²é»
            }
        """
        critical_gaps = []
        moderate_gaps = []
        minor_gaps = []

        for gap in knowledge_gaps:
            accuracy = gap.get("accuracy", 0)
            attempts = gap.get("total_attempts", 0)

            if accuracy < 40 and attempts >= 5:
                critical_gaps.append(gap)
            elif accuracy < 60 and attempts >= 3:
                moderate_gaps.append(gap)
            else:
                minor_gaps.append(gap)

        return {
            "critical_gaps": critical_gaps,
            "moderate_gaps": moderate_gaps,
            "minor_gaps": minor_gaps
        }

    def recommend_topics(self,
                        failed_operations: Optional[List[Dict]] = None,
                        knowledge_gaps: Optional[List[Dict]] = None,
                        max_recommendations: int = 5) -> List[Dict]:
        """
        æ¨è–¦ç†è«–è¤‡ç¿’ä¸»é¡Œ

        Args:
            failed_operations: å¤±æ•—æ“ä½œåˆ—è¡¨
            knowledge_gaps: çŸ¥è­˜ç›²é»åˆ—è¡¨
            max_recommendations: æœ€å¤šæ¨è–¦æ•¸é‡

        Returns:
            æ¨è–¦ä¸»é¡Œåˆ—è¡¨ï¼Œæ¯é …åŒ…å«ï¼š
            {
                "topic": str,
                "priority": str,  # critical/high/medium/low
                "reason": str,
                "related_operations": [...]
            }
        """
        recommendations = []
        topic_scores = defaultdict(lambda: {"score": 0, "reasons": [], "operations": []})

        # 1. æ ¹æ“šå¤±æ•—æ“ä½œæ¨è–¦
        if failed_operations:
            failure_analysis = self.analyze_failed_operations(failed_operations)

            for category, count in failure_analysis["failure_by_category"].items():
                mapping = self.OPERATION_TOPIC_MAPPING[category]
                priority_score = self._get_priority_score(mapping["priority"])

                for topic in mapping["topics"]:
                    topic_scores[topic]["score"] += count * priority_score
                    topic_scores[topic]["reasons"].append(
                        f"åœ¨{category}ç›¸é—œæ“ä½œä¸­å¤±æ•—{count}æ¬¡"
                    )
                    topic_scores[topic]["priority"] = mapping["priority"]

        # 2. æ ¹æ“šçŸ¥è­˜ç›²é»æ¨è–¦
        if knowledge_gaps:
            gap_analysis = self.analyze_knowledge_gaps(knowledge_gaps)

            # åš´é‡ç›²é»åŠ æ¬Šæœ€é«˜
            for gap in gap_analysis["critical_gaps"]:
                topic = gap["topic"]
                topic_scores[topic]["score"] += 10
                topic_scores[topic]["reasons"].append(
                    f"è©²ä¸»é¡Œæ­£ç¢ºç‡åƒ…{gap['accuracy']}%ï¼ˆåš´é‡ç›²é»ï¼‰"
                )
                topic_scores[topic]["priority"] = "critical"

            # ä¸­ç­‰ç›²é»
            for gap in gap_analysis["moderate_gaps"]:
                topic = gap["topic"]
                topic_scores[topic]["score"] += 5
                topic_scores[topic]["reasons"].append(
                    f"è©²ä¸»é¡Œæ­£ç¢ºç‡{gap['accuracy']}%ï¼ˆéœ€åŠ å¼·ï¼‰"
                )
                if "priority" not in topic_scores[topic]:
                    topic_scores[topic]["priority"] = "high"

        # 3. æ’åºä¸¦ç”Ÿæˆæ¨è–¦
        sorted_topics = sorted(
            topic_scores.items(),
            key=lambda x: (
                self._get_priority_score(x[1].get("priority", "low")),
                x[1]["score"]
            ),
            reverse=True
        )

        for topic, data in sorted_topics[:max_recommendations]:
            recommendations.append({
                "topic": topic,
                "priority": data.get("priority", "medium"),
                "score": data["score"],
                "reasons": data["reasons"],
                "recommendation": self._generate_recommendation_text(topic, data)
            })

        # è¨˜éŒ„æ¨è–¦æ­·å²
        self.recommendation_history.append({
            "timestamp": self._get_timestamp(),
            "recommendations": recommendations
        })

        return recommendations

    def _get_priority_score(self, priority: str) -> int:
        """å„ªå…ˆç´šè½‰åˆ†æ•¸"""
        priority_map = {
            "critical": 100,
            "high": 50,
            "medium": 20,
            "low": 10
        }
        return priority_map.get(priority, 10)

    def _generate_recommendation_text(self, topic: str, data: Dict) -> str:
        """ç”Ÿæˆæ¨è–¦æ–‡å­—"""
        priority = data.get("priority", "medium")
        reasons = data["reasons"]

        if priority == "critical":
            prefix = "âš ï¸ å¼·çƒˆå»ºè­°ç«‹å³è¤‡ç¿’"
        elif priority == "high":
            prefix = "ğŸ“Œ å»ºè­°å„ªå…ˆè¤‡ç¿’"
        else:
            prefix = "ğŸ’¡ å»ºè­°è¤‡ç¿’"

        reason_text = "ã€".join(reasons[:2])  # æœ€å¤šé¡¯ç¤º2å€‹åŸå› 

        return f"{prefix}ã€Œ{topic}ã€- {reason_text}"

    def generate_learning_path(self, recommendations: List[Dict]) -> List[Dict]:
        """
        ç”Ÿæˆå€‹æ€§åŒ–å­¸ç¿’è·¯å¾‘

        Args:
            recommendations: æ¨è–¦ä¸»é¡Œåˆ—è¡¨

        Returns:
            å­¸ç¿’è·¯å¾‘ï¼ŒæŒ‰å„ªå…ˆç´šå’Œä¾è³´é—œä¿‚æ’åº
        """
        # ä¸»é¡Œä¾è³´é—œä¿‚ï¼ˆæŸäº›ä¸»é¡Œéœ€è¦å…ˆå­¸å…¶ä»–ä¸»é¡Œï¼‰
        dependencies = {
            "CVDåŸç†": [],
            "åŒ–å­¸åæ‡‰": ["CVDåŸç†"],
            "å†·å»ç³»çµ±åŸç†": [],
            "ç†±ç®¡ç†åŸºç¤": ["å†·å»ç³»çµ±åŸç†"],
            "çœŸç©ºç³»çµ±åŸç†": [],
            "çœŸç©ºæ³µæ“ä½œ": ["çœŸç©ºç³»çµ±åŸç†"],
            "å°æº–ç³»çµ±åŸç†": [],
            "ç²¾å¯†å®šä½": ["å°æº–ç³»çµ±åŸç†"]
        }

        learning_path = []
        completed_topics = set()

        # æŒ‰å„ªå…ˆç´šåˆ†çµ„
        critical = [r for r in recommendations if r["priority"] == "critical"]
        high = [r for r in recommendations if r["priority"] == "high"]
        medium = [r for r in recommendations if r["priority"] == "medium"]
        low = [r for r in recommendations if r["priority"] == "low"]

        # è™•ç†æ¯å€‹å„ªå…ˆç´šçµ„
        for group in [critical, high, medium, low]:
            for rec in group:
                topic = rec["topic"]

                # æª¢æŸ¥ä¾è³´
                deps = dependencies.get(topic, [])
                missing_deps = [d for d in deps if d not in completed_topics]

                if missing_deps:
                    # å…ˆåŠ å…¥ç¼ºå°‘çš„ä¾è³´ä¸»é¡Œ
                    for dep in missing_deps:
                        if dep not in completed_topics:
                            learning_path.append({
                                "topic": dep,
                                "priority": "prerequisite",
                                "reason": f"ã€Œ{topic}ã€çš„å‰ç½®çŸ¥è­˜"
                            })
                            completed_topics.add(dep)

                # åŠ å…¥ä¸»è¦ä¸»é¡Œ
                learning_path.append({
                    "topic": topic,
                    "priority": rec["priority"],
                    "reasons": rec["reasons"],
                    "estimated_time_minutes": self._estimate_study_time(topic)
                })
                completed_topics.add(topic)

        return learning_path

    def _estimate_study_time(self, topic: str) -> int:
        """ä¼°ç®—å­¸ç¿’æ™‚é–“ï¼ˆåˆ†é˜ï¼‰"""
        # æ ¹æ“šä¸»é¡Œè¤‡é›œåº¦ä¼°ç®—
        complex_topics = ["CVDåŸç†", "åŒ–å­¸åæ‡‰", "çœŸç©ºç³»çµ±åŸç†", "PIDæ§åˆ¶"]
        medium_topics = ["æº«æ§ç³»çµ±åŸç†", "å£“åŠ›æ§åˆ¶åŸç†", "å°æº–ç³»çµ±åŸç†"]

        if topic in complex_topics:
            return 45
        elif topic in medium_topics:
            return 30
        else:
            return 20

    def should_trigger_recommendation(self,
                                     recent_failures: List[Dict],
                                     failure_threshold: int = 3) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²è§¸ç™¼æ¨è–¦

        Args:
            recent_failures: æœ€è¿‘çš„å¤±æ•—è¨˜éŒ„
            failure_threshold: å¤±æ•—æ¬¡æ•¸é–¾å€¼

        Returns:
            æ˜¯å¦æ‡‰è©²æ¨è–¦
        """
        if len(recent_failures) >= failure_threshold:
            return True

        # æª¢æŸ¥é€£çºŒå¤±æ•—
        if len(recent_failures) >= 3:
            # å¦‚æœæœ€è¿‘3æ¬¡éƒ½å¤±æ•—ï¼Œä¹Ÿè§¸ç™¼
            return True

        return False

    def _get_timestamp(self) -> str:
        """ç²å–æ™‚é–“æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()

    def export_recommendations(self, output_file: str, recommendations: List[Dict]):
        """
        åŒ¯å‡ºæ¨è–¦çµæœ

        Args:
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            recommendations: æ¨è–¦åˆ—è¡¨
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": self._get_timestamp(),
                "recommendations": recommendations
            }, f, ensure_ascii=False, indent=2)


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    print("=== Smart Recommender ä½¿ç”¨ç¯„ä¾‹ ===\n")

    # 1. å‰µå»ºæ¨è–¦å™¨
    recommender = SmartRecommender()

    # 2. æ¨¡æ“¬å¤±æ•—æ“ä½œ
    failed_operations = [
        {"operation": "æª¢æŸ¥å†·å»æ°´æµé‡æ˜¯å¦æ­£å¸¸", "topic": "å†·å»ç³»çµ±"},
        {"operation": "èª¿æ•´çœŸç©ºå£“åŠ›åˆ°æ¨™æº–å€¼", "topic": "çœŸç©ºç³»çµ±"},
        {"operation": "æª¢æŸ¥å†·å»é¢¨æ‰‡é‹è½‰", "topic": "å†·å»ç³»çµ±"},
        {"operation": "æª¢æ¸¬çœŸç©ºæ´©æ¼", "topic": "çœŸç©ºç³»çµ±"},
        {"operation": "æ ¡æº–å°æº–ç³»çµ±", "topic": "å°æº–ç³»çµ±"}
    ]

    # 3. æ¨¡æ“¬çŸ¥è­˜ç›²é»
    knowledge_gaps = [
        {"topic": "å†·å»ç³»çµ±", "accuracy": 35, "total_attempts": 6, "error_count": 4},
        {"topic": "çœŸç©ºç³»çµ±", "accuracy": 55, "total_attempts": 4, "error_count": 2},
        {"topic": "CVD", "accuracy": 45, "total_attempts": 5, "error_count": 3}
    ]

    # 4. åˆ†æå¤±æ•—æ“ä½œ
    print("åˆ†æå¤±æ•—æ“ä½œ...")
    failure_analysis = recommender.analyze_failed_operations(failed_operations)
    print(f"ç¸½å¤±æ•—æ¬¡æ•¸: {failure_analysis['total_failures']}")
    print(f"å¤±æ•—é¡åˆ¥åˆ†å¸ƒ: {failure_analysis['failure_by_category']}")
    print()

    # 5. åˆ†æçŸ¥è­˜ç›²é»
    print("åˆ†æçŸ¥è­˜ç›²é»...")
    gap_analysis = recommender.analyze_knowledge_gaps(knowledge_gaps)
    print(f"åš´é‡ç›²é»: {len(gap_analysis['critical_gaps'])} å€‹")
    print(f"ä¸­ç­‰ç›²é»: {len(gap_analysis['moderate_gaps'])} å€‹")
    print()

    # 6. ç”Ÿæˆæ¨è–¦
    print("ç”Ÿæˆæ¨è–¦ä¸»é¡Œ...")
    recommendations = recommender.recommend_topics(
        failed_operations=failed_operations,
        knowledge_gaps=knowledge_gaps,
        max_recommendations=5
    )

    print(f"\næ¨è–¦ {len(recommendations)} å€‹ä¸»é¡Œ:\n")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec['recommendation']}")
        print(f"   å„ªå…ˆç´š: {rec['priority']}")
        print(f"   åˆ†æ•¸: {rec['score']}")
        print()

    # 7. ç”Ÿæˆå­¸ç¿’è·¯å¾‘
    print("ç”Ÿæˆå­¸ç¿’è·¯å¾‘...")
    learning_path = recommender.generate_learning_path(recommendations)

    print(f"\nå»ºè­°å­¸ç¿’é †åº (å…± {len(learning_path)} å€‹ä¸»é¡Œ):\n")
    total_time = 0
    for i, step in enumerate(learning_path, 1):
        time = step.get("estimated_time_minutes", 0)
        total_time += time
        print(f"{i}. {step['topic']} ({time}åˆ†é˜)")
        if "reasons" in step:
            print(f"   åŸå› : {step['reasons'][0]}")

    print(f"\né ä¼°ç¸½å­¸ç¿’æ™‚é–“: {total_time} åˆ†é˜ ({total_time/60:.1f} å°æ™‚)")

    # 8. æª¢æŸ¥æ˜¯å¦æ‡‰è©²è§¸ç™¼æ¨è–¦
    print("\næª¢æŸ¥è§¸ç™¼æ¢ä»¶...")
    should_trigger = recommender.should_trigger_recommendation(failed_operations)
    print(f"æ‡‰è©²è§¸ç™¼æ¨è–¦: {'æ˜¯' if should_trigger else 'å¦'}")
